{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"./src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ot as pot\n",
    "import torch\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from DANN import DANN\n",
    "from DAN import DAN\n",
    "from CORAL import coral\n",
    "from optimalTransport1D import optimalTransport1D\n",
    "from nnModel import FC_embedding, EmbeddingModel\n",
    "\n",
    "from utils import *\n",
    "from io_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DanseNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(input_dim, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(16, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.hidden_rep = self.input_layer(inputs)\n",
    "        return self.output_layer(self.hidden_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## execution environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert categorical features to embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = np.load(\"./data/mobile_trans.npy\")\n",
    "target = np.load(\"./data/desktop_trans.npy\")\n",
    "source_label = np.load(\"./data/mobile_label.npy\")\n",
    "target_label = np.load(\"./data/desktop_label.npy\")\n",
    "\n",
    "with open(\"./data/embedding_dict_kaggle.pkl\", \"rb\") as file:\n",
    "    embedding_dict = pickle.load(file)\n",
    "    \n",
    "# exclude target unique modality\n",
    "exclude_index = []\n",
    "for i in range(8):\n",
    "    target_modality = np.unique(target[:, i])\n",
    "    source_modality = np.unique(source[:, i])\n",
    "    exclude = [m for m in target_modality if m not in source_modality]\n",
    "    exclude_index.append(np.isin(target[:, i], exclude))\n",
    "target_cate = target[~np.any(exclude_index, axis=0)]\n",
    "target_num_label = target_label[~np.any(exclude_index, axis=0)]\n",
    "\n",
    "source_cate_embedding = []\n",
    "for i in range(8):\n",
    "    source_cate_embedding.append(embedding_dict[i][source[:, i].astype(int)])\n",
    "    \n",
    "target_cate_embedding = []\n",
    "for i in range(8):\n",
    "    target_cate_embedding.append(embedding_dict[i][target_cate[:, i].astype(int)])\n",
    "    \n",
    "source_num = np.concatenate(source_cate_embedding, axis=1)\n",
    "source_num = np.c_[source_num, source[:, 8:]]\n",
    "\n",
    "target_num = np.concatenate(target_cate_embedding, axis=1)\n",
    "target_num = np.c_[target_num, target_cate[:, 8:]]\n",
    "\n",
    "target_num_size = int(target_num.shape[0] // 12)\n",
    "\n",
    "del(target)\n",
    "del(target_label)\n",
    "gc.collect()\n",
    "\n",
    "target = target_cate\n",
    "target_label = target_num_label\n",
    "target_size = target_num_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cate_adaptation(target, source):\n",
    "    \"\"\"\n",
    "    input: target & source with categorical features\n",
    "    return: adapted embed target\n",
    "    \"\"\"\n",
    "    ot_plans = []\n",
    "    source_modalities = []\n",
    "    target_modalities = []\n",
    "\n",
    "    for c in range(8):\n",
    "        sim, modality = of_uni_cate(np.r_[target[:,c], source[:,c]])\n",
    "        distance = similarity_to_dissimilarity(sim)\n",
    "\n",
    "        target_modality, counts = np.unique(target[:,c], return_counts=True)\n",
    "        target_density = counts / counts.sum()\n",
    "        target_modalities.append(target_modality)\n",
    "\n",
    "        source_modality, counts = np.unique(source[:,c], return_counts=True)\n",
    "        source_density = counts / counts.sum()\n",
    "        source_modalities.append(source_modality)\n",
    "\n",
    "        Gs = pot.emd(target_density.tolist(), source_density.tolist(), \n",
    "                     distance[np.where(np.in1d(modality, target_modality))[0]][:,np.where(np.in1d(modality, source_modality))[0]].tolist())\n",
    "\n",
    "        norm_array = Gs.sum(axis=1)\n",
    "        norm_array[norm_array==0] = 1\n",
    "        ot_plan = (Gs.T / norm_array).T\n",
    "        ot_plans.append(ot_plan)\n",
    "\n",
    "\n",
    "    target_embedding = []\n",
    "    for c, ot_plan in enumerate(ot_plans):\n",
    "        trans_matrix = np.zeros((embedding_dict[c].shape[0], embedding_dict[c].shape[0]))\n",
    "        for i, target_index in enumerate(target_modalities[c]):\n",
    "            trans_matrix[int(target_index), list(map(int, source_modalities[c]))] = ot_plan[i]\n",
    "\n",
    "        target_embedding.append(trans_matrix.dot(embedding_dict[c]))\n",
    "\n",
    "    target_cate_embedding = []\n",
    "    for i in range(8):\n",
    "        target_cate_embedding.append(target_embedding[i][target[:, i].astype(int)])\n",
    "\n",
    "    target_cate_num = np.concatenate(target_cate_embedding, axis=1)\n",
    "    target_cate_num = np.c_[target_cate_num, target[:, 8:]]\n",
    "    return target_cate_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chose the subset of data tu investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0 #0, 1, 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_splits = []\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=12345)\n",
    "for i, (train_index, valid_index) in enumerate(kf.split(source)):\n",
    "    source_splits.append((train_index, valid_index))\n",
    "\n",
    "train_index, valid_index = source_splits[s]\n",
    "\n",
    "xs, ys = source_num[train_index], source_label[train_index]\n",
    "xv, yv = source_num[valid_index], source_label[valid_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create navie source black-box model (Neural networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12345)\n",
    "try:\n",
    "    clf = load_model(\"./model/kaggle_nn_{}\".format(s))\n",
    "except:\n",
    "    dansnet = DanseNet(input_dim=xs.shape[1], output_dim=1)\n",
    "    clf = DAN(dansnet, device=torch.device(\"cuda\"))\n",
    "    clf.fit(xs, ys, xs, xv, yv, epoch=100, batch_size=128, lr=0.01, beta=0, early_stop=False, verbose=True)\n",
    "    save_model(clf, \"./model/kaggle_nn_{}\".format(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptation methods require no retraining:\n",
    "* Identical\n",
    "* CORAL\n",
    "* 1D OT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identical\n",
    "pred_test = clf.predict_prob(target_num)\n",
    "performance(pred_test, target_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORAL\n",
    "x_coral = coral(target_num, xs)\n",
    "pred_coral = clf.predict_prob(x_coral)\n",
    "performance(pred_coral, target_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D OT num\n",
    "opt = optimalTransport1D()\n",
    "tsf, _ = opt.fit_transform(target_num[:,17:], xs[:,17:], njobs=20)\n",
    "x_ot_num = np.c_[target_num[:,:17], tsf]\n",
    "pred_num = clf.predict_prob(x_ot_num)\n",
    "performance(pred_num, target_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D OT cate\n",
    "x_ot_cate = cate_adaptation(target, source[train_index])\n",
    "pred_cate = clf.predict_prob(x_ot_cate)\n",
    "performance(pred_cate, target_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D OT\n",
    "x_ot = np.c_[x_ot_cate[:,:17], tsf]\n",
    "pred_ot = clf.predict_prob(x_ot)\n",
    "performance(pred_ot, target_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptation methods require retraining:\n",
    "* DANN\n",
    "* DAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAN\n",
    "np.random.seed(12345)\n",
    "torch.manual_seed(12345)\n",
    "try:\n",
    "    clf = load_model(\"./model/kaggle_dan_{}\".format(s))\n",
    "except:\n",
    "    dansnet = DanseNet(input_dim=xs.shape[1], output_dim=1)\n",
    "    clf = DAN(dansnet, device=torch.device(\"cuda\"))\n",
    "    indext = reduce_dataset(target_num, xs)\n",
    "    clf.fit(xs, ys, target_num[indext], xv, yv, epoch=100, batch_size=128, lr=0.01, beta=0.5, early_stop=False, verbose=False)\n",
    "    save_model(clf, \"./model/kaggle_dan_{}\".format(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAN\n",
    "pred_dan = clf.predict_prob(target_num)\n",
    "performance(pred_dan, target_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DANN \n",
    "np.random.seed(12345)\n",
    "torch.manual_seed(12345)\n",
    "if s == 0:\n",
    "    e, b, a = 50, 1.0, 50\n",
    "elif s == 1:\n",
    "    e, b, a = 50, 1.0, 100\n",
    "elif s == 2:\n",
    "    e, b, a = 100, 0.5, 200\n",
    "else:\n",
    "    e, b, a = 50, 1.0, 200\n",
    "try:\n",
    "    clf = load_model(\"./model/kaggle_dann_{}\".format(s))\n",
    "except:\n",
    "    dansnet = DanseNet(input_dim=xs.shape[1], output_dim=1)\n",
    "    clf = DANN(dansnet, device=torch.device(\"cuda\"))\n",
    "    indext = reduce_dataset(target_num, xs)\n",
    "    clf.fit(xs, ys, target_num[indext], xv, yv, epoch=e, batch_size=128, lr=0.01, beta=b, alpha=a,\n",
    "            early_stop=False, verbose=False)\n",
    "    save_model(clf, \"./model/kaggle_dann_{}\".format(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dann = clf.predict_prob(target_num)\n",
    "performance(pred_dann, target_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weakly supervised adaptation with feature selection for neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.01 # percentage of labeled target data\n",
    "repitition = 30 # experiments repetition\n",
    "n_sample = 200 # number of bootstrap examples\n",
    "\n",
    "cate_fea = [(0,), (1, 2, 3), (4,), (5, 6, 7, 8), (9, 10, 11), (12,), (13, 14, 15), (16,)]\n",
    "num_fea = [(i, ) for i in range(17, 129)]\n",
    "\n",
    "for s in range(4):\n",
    "    # Load Dataset\n",
    "    train_index, valid_index = source_splits[s]\n",
    "    xs, ys = source_num[train_index], source_label[train_index]\n",
    "    xv, yv = source_num[valid_index], source_label[valid_index]\n",
    "\n",
    "    # Load Model\n",
    "    clf = load_model(\"./model/kaggle_nn_{}\".format(s))\n",
    "    \n",
    "    # Numerical Adaptation\n",
    "    opt = optimalTransport1D()\n",
    "    tsf, _ = opt.fit_transform(target_num[:,17:], xs[:,17:], njobs=20)\n",
    "\n",
    "    # Categorical Adaptation\n",
    "    x_ot_cate = cate_adaptation(target, source[train_index])\n",
    "    x_ot = np.c_[x_ot_cate[:,:17], tsf]\n",
    "\n",
    "    bootstrap_perf = []\n",
    "    for i in range(repitition):\n",
    "        # Sample\n",
    "        choice_range = range(target_num.shape[0])\n",
    "        n = int(target_num.shape[0] * ratio)\n",
    "        index = np.random.choice(choice_range, n, replace=False)\n",
    "        \n",
    "        # Compute perf_list and feature_list\n",
    "        perf_list, feature_list, pred_list, perf_dist_list, index_list = greedy_search(clf, target_num[index], x_ot[index], \n",
    "                                                                           target_label[index], \n",
    "                                                                           explore_features=cate_fea + num_fea, \n",
    "                                                                           n_sample=n_sample,\n",
    "                                                                           verbose=False)\n",
    "\n",
    "        save_model(perf_list, \"./model/bootstrap_perf_list_{}_{}_{}\".format(ratio, s, i))\n",
    "        save_model(feature_list, \"./model/bootstrap_feature_list_{}_{}_{}\".format(ratio, s, i))\n",
    "        save_model(pred_list, \"./model/bootstrap_pred_list_{}_{}_{}\".format(ratio, s, i))\n",
    "        save_model(index, \"./model/bootstrap_index_{}_{}_{}\".format(ratio, s, i))\n",
    "        save_model(perf_dist_list, \"./model/bootstrap_perf_dist_list_{}_{}_{}\".format(ratio, s, i))\n",
    "        save_model(index_list, \"./model/bootstrap_index_list_{}_{}_{}\".format(ratio, s, i))\n",
    "        \n",
    "        # Perf on all test data\n",
    "        pred = best_prediction(clf, target_num, x_ot, feature_list, len(feature_list)-1, repeat=1)\n",
    "        perf = performance(pred, target_label)\n",
    "        bootstrap_perf.append(perf)\n",
    "        print(\"Period:\", s, \"Bootstrap performance:\", perf, \"Selected features:\", len(feature_list))\n",
    "\n",
    "    save_model(bootstrap_perf, \"./model/bootstrap_perf_{}_{}\".format(ratio, s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create navie source black-box model (LGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = source[train_index], source_label[train_index]\n",
    "xv, yv = source[valid_index], source_label[valid_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    clf = load_model(\"./model/kaggle_lgb_{}\".format(s))\n",
    "except:\n",
    "    lgb_train = lgb.Dataset(xs, ys, categorical_feature=range(8))\n",
    "    lgb_valid = lgb.Dataset(xv, yv, categorical_feature=range(8))\n",
    "\n",
    "    params = {\n",
    "        'boosting': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'learning_rate': 0.04,\n",
    "        'max_depth': 3,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'scale_pos_weight': 1,\n",
    "        'reg_alpha': 0,\n",
    "        'reg_lambda': 0,\n",
    "        'random_state': 12345\n",
    "    }\n",
    "\n",
    "    clf = lgb.train(params, lgb_train, valid_sets=[lgb_train, lgb_valid], num_boost_round=5000, \n",
    "                    early_stopping_rounds=50, verbose_eval=10)\n",
    "    save_model(clf, \"./model/kaggle_lgb_{}\".format(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptation methods require no retraining:\n",
    "* Identical\n",
    "* CORAL\n",
    "* 1D OT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identical\n",
    "pred_test = clf.predict(target)\n",
    "performance(pred_test, target_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORAL\n",
    "tsf = coral(target[:,8:], xs[:,8:])\n",
    "x_coral = np.c_[target[:,:8], tsf]\n",
    "pred_coral = clf.predict(x_coral)\n",
    "performance(pred_coral, target_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D OT num\n",
    "opt = optimalTransport1D()\n",
    "tsf, w_distance = opt.fit_transform(target[:,8:], xs[:,8:], njobs=20)\n",
    "x_ot_num = np.c_[target[:,:8], tsf]\n",
    "pred_num = clf.predict(x_ot_num)\n",
    "performance(pred_num, target_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D OT cate\n",
    "np.random.seed(12345)\n",
    "\n",
    "repeat = 10\n",
    "ot_plans = []\n",
    "transport_plan = []\n",
    "source_modalities = []\n",
    "target_modalities = []\n",
    "\n",
    "# Get transformation plan\n",
    "for c in range(8):\n",
    "    sim, modality = of_uni_cate(np.r_[target[:,c], xs[:,c]])\n",
    "    distance = similarity_to_dissimilarity(sim)\n",
    "    \n",
    "    target_modality, counts = np.unique(target[:,c], return_counts=True)\n",
    "    target_density = counts / counts.sum()\n",
    "    target_modalities.append(target_modality)\n",
    "\n",
    "    source_modality, counts = np.unique(xs[:,c], return_counts=True)\n",
    "    source_density = counts / counts.sum()\n",
    "    source_modalities.append(source_modality)\n",
    "\n",
    "    Gs = pot.emd(target_density.tolist(), source_density.tolist(), \n",
    "                 distance[np.where(np.in1d(modality, target_modality))[0]][:,np.where(np.in1d(modality, source_modality))[0]].tolist())\n",
    "\n",
    "    norm_array = Gs.sum(axis=1)\n",
    "    norm_array[norm_array==0] = 1\n",
    "    ot_plan = (Gs.T / norm_array).T\n",
    "    ot_plans.append(ot_plan)\n",
    "\n",
    "    mapping = {}\n",
    "    for m in target_modality:\n",
    "        index = np.where(target_modality==m)[0][0]\n",
    "        mapping[m] = ot_plan[index]\n",
    "\n",
    "    transport_plan.append(mapping)\n",
    "\n",
    "\n",
    "# Perform stochastical transformation\n",
    "preds = []\n",
    "for r in range(repeat):\n",
    "    data = target.copy()\n",
    "\n",
    "    for c in range(8):\n",
    "        for m, values in transport_plan[c].items():\n",
    "            if np.sum(target[:, c]==m) > 0:\n",
    "                data[target[:, c]==m, c] = source_modalities[c][\n",
    "                    np.random.choice(\n",
    "                    len(source_modalities[c]), \n",
    "                    size=np.sum(target[:, c]==m), \n",
    "                    p=values)]\n",
    "\n",
    "    pred = clf.predict(data)\n",
    "    preds.append(pred)\n",
    "    \n",
    "# Get prediction results\n",
    "pred_cate = np.array(preds).mean(axis=0)\n",
    "performance(pred_cate, target_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D OT\n",
    "preds = []\n",
    "for r in range(repeat):\n",
    "    data = x_ot_num.copy()\n",
    "\n",
    "    for c in range(8):\n",
    "        for m, values in transport_plan[c].items():\n",
    "            if np.sum(x_ot_num[:, c]==m) > 0:\n",
    "                data[x_ot_num[:, c]==m, c] = source_modalities[c][\n",
    "                    np.random.choice(\n",
    "                    len(source_modalities[c]), \n",
    "                    size=np.sum(x_ot_num[:, c]==m), \n",
    "                    p=values)]\n",
    "\n",
    "    pred = clf.predict(data)\n",
    "    preds.append(pred)\n",
    "\n",
    "# Get prediction results\n",
    "pred_ot = np.array(preds).mean(axis=0)\n",
    "performance(pred_ot, target_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weakly supervised adaptation with feature selection for LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.01 # percentage of labeled target data\n",
    "repitition = 30 # experiments repetition\n",
    "n_sample = 200 # number of bootstrap examples\n",
    "repeat = 10 # number of stochastic transformation\n",
    "\n",
    "num_fea = [(i, ) for i in range(120)]\n",
    "\n",
    "for s in range(4):\n",
    "    # Load Dataset\n",
    "    train_index, valid_index = source_splits[s]\n",
    "    xs, ys = source[train_index], source_label[train_index]\n",
    "    xv, yv = source[valid_index], source_label[valid_index]\n",
    "\n",
    "    # Load Models\n",
    "    clf = load_model(\"./model/kaggle_lgb_{}\".format(s))\n",
    "    clf.predict_prob = clf.predict\n",
    "\n",
    "    # Numerical transformation\n",
    "    opt = optimalTransport1D()\n",
    "    tsf, w_distance = opt.fit_transform(target[:,8:], xs[:,8:], njobs=20)\n",
    "    x_ot_num = np.c_[target[:,:8], tsf]\n",
    "\n",
    "    # Stochastic categorical transformation\n",
    "    ot_plans = []\n",
    "    transport_plan = []\n",
    "    source_modalities = []\n",
    "    target_modalities = []\n",
    "\n",
    "    # Get transformation plan\n",
    "    for c in range(8):\n",
    "        sim, modality = of_uni_cate(np.r_[target[:,c], xs[:,c]])\n",
    "        distance = similarity_to_dissimilarity(sim)\n",
    "\n",
    "        target_modality, counts = np.unique(target[:,c], return_counts=True)\n",
    "        target_density = counts / counts.sum()\n",
    "        target_modalities.append(target_modality)\n",
    "\n",
    "        source_modality, counts = np.unique(xs[:,c], return_counts=True)\n",
    "        source_density = counts / counts.sum()\n",
    "        source_modalities.append(source_modality)\n",
    "\n",
    "        Gs = pot.emd(target_density.tolist(), source_density.tolist(), \n",
    "                     distance[np.where(np.in1d(modality, target_modality))[0]][:,np.where(np.in1d(modality, source_modality))[0]].tolist())\n",
    "\n",
    "        norm_array = Gs.sum(axis=1)\n",
    "        norm_array[norm_array==0] = 1\n",
    "        ot_plan = (Gs.T / norm_array).T\n",
    "        ot_plans.append(ot_plan)\n",
    "\n",
    "        mapping = {}\n",
    "        for m in target_modality:\n",
    "            index = np.where(target_modality==m)[0][0]\n",
    "            mapping[m] = ot_plan[index]\n",
    "\n",
    "        transport_plan.append(mapping)\n",
    "\n",
    "    bootstrap_perf = []\n",
    "    for i in range(repitition):\n",
    "        # Sample labeledtarget data\n",
    "        choice_range = range(target.shape[0])\n",
    "        n = int(target.shape[0] * ratio)\n",
    "        index = np.random.choice(choice_range, n, replace=False)\n",
    "\n",
    "        # Perform stochastical transformation\n",
    "        cate_adapt = None\n",
    "        for r in range(repeat):\n",
    "            data = x_ot_num[index].copy()\n",
    "            for c in range(8):\n",
    "                for m, values in transport_plan[c].items():\n",
    "                    if np.sum(x_ot_num[index, c]==m) > 0:\n",
    "                        data[x_ot_num[index, c]==m, c] = source_modalities[c][\n",
    "                            np.random.choice(\n",
    "                            len(source_modalities[c]), \n",
    "                            size=np.sum(x_ot_num[index, c]==m), \n",
    "                            p=values)]\n",
    "                    \n",
    "            if cate_adapt is None:\n",
    "                cate_adapt = data\n",
    "            else:\n",
    "                cate_adapt = np.r_[cate_adapt, data]\n",
    "\n",
    "        # Compute perf_list and feature_list\n",
    "        perf_list, feature_list, pred_list, perf_dist_list, index_list = greedy_search_cate(clf, \n",
    "                                                                                            target[np.tile(index, repeat)], \n",
    "                                                                                            cate_adapt, \n",
    "                                                                                            target_label[index], \n",
    "                                                                                            explore_features=num_fea, \n",
    "                                                                                            repeat=repeat,\n",
    "                                                                                            n_sample=n_sample,\n",
    "                                                                                            verbose=False)\n",
    "\n",
    "        save_model(perf_list, \"./model/cate_bootstrap_perf_list_{}_{}_{}\".format(ratio, s, i))\n",
    "        save_model(feature_list, \"./model/cate_bootstrap_feature_list_{}_{}_{}\".format(ratio, s, i))\n",
    "        save_model(pred_list, \"./model/cate_bootstrap_pred_list_{}_{}_{}\".format(ratio, s, i))\n",
    "        save_model(index, \"./model/cate_bootstrap_index_{}\".format(ratio, s, i))\n",
    "        save_model(perf_dist_list, \"./model/cate_bootstrap_perf_dist_list_{}_{}_{}\".format(ratio, s, i))\n",
    "        save_model(index_list, \"./model/cate_bootstrap_index_list_{}_{}_{}\".format(ratio, s, i))\n",
    "\n",
    "        # Adapt selected features\n",
    "        x_ot = None\n",
    "        for r in range(repeat):\n",
    "            data = x_ot_num.copy()\n",
    "            for c in range(8):\n",
    "                for m, values in transport_plan[c].items():\n",
    "                    if np.sum(x_ot_num[:, c]==m) > 0:\n",
    "                        data[x_ot_num[:, c]==m, c] = source_modalities[c][\n",
    "                            np.random.choice(\n",
    "                            len(source_modalities[c]), \n",
    "                            size=np.sum(x_ot_num[:, c]==m), \n",
    "                            p=values)]\n",
    "            if x_ot is None:\n",
    "                x_ot = data\n",
    "            else:\n",
    "                x_ot = np.r_[x_ot, data]\n",
    "\n",
    "        # Perf on all test data\n",
    "        pred = best_prediction(clf, np.tile(target, (repeat, 1)), x_ot, feature_list, len(feature_list)-1, repeat=repeat)\n",
    "        perf = performance(pred, target_label)\n",
    "        bootstrap_perf.append(perf)\n",
    "        print(\"Period:\", s, \"Bootstrap performance:\", perf, \"Selected features:\", len(feature_list))\n",
    "    save_model(bootstrap_perf, \"./model/cate_bootstrap_perf_{}_{}\".format(ratio, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
